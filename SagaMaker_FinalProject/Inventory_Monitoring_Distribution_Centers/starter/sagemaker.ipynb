{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Title\n",
    "**TODO**: Give a helpful introduction to what this notebook is for. Remember that comments, explanations and good documentation make your project informative and professional.\n",
    "\n",
    "**Note:** This notebook has a bunch of code and markdown cells with TODOs that you have to complete. These are meant to be helpful guidelines for you to finish your project while meeting the requirements in the project rubrics. Feel free to change the order of the TODO's and/or use more than one cell to complete all the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Install any packages that you might need\n",
    "\n",
    "%pip install protobuf==3.20.3\n",
    "%pip install smdebug\n",
    "%pip install torch\n",
    "%pip install -U sagemaker\n",
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-03 20:53:31.739 DuLam:21916 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import any packages that you might need\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "import sagemaker\n",
    "import sagemaker.image_uris\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.debugger import Rule, rule_configs, ProfilerRule, ProfilerConfig, FrameworkProfile, DebuggerHookConfig\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "from smdebug.trials import create_trial\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.serializers import IdentitySerializer\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.inputs import TrainingInput\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "**TODO:** Run the cell below to download the data.\n",
    "\n",
    "The cell below creates a folder called `train_data`, downloads training data and arranges it in subfolders. Each of these subfolders contain images where the number of objects is equal to the name of the folder. For instance, all images in folder `1` has images with 1 object in them. Images are not divided into training, testing or validation sets. If you feel like the number of samples are not enough, you can always download more data (instructions for that can be found [here](https://registry.opendata.aws/amazon-bin-imagery/)). However, we are not acessing you on the accuracy of your final trained model, but how you create your machine learning engineering pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the SageMaker execution role\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# Get the current AWS region\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# Create a SageMaker session\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# Set the default S3 bucket\n",
    "default_bucket = session.default_bucket()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 1 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1228 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [14:46<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 2 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2299/2299 [28:28<00:00,  1.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 3 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2666/2666 [31:41<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 4 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2373/2373 [30:32<00:00,  1.30it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 5 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [22:02<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to download and arrange data from S3\n",
    "train_data_dir = 'train_data'\n",
    "\n",
    "def download_and_arrange_data():\n",
    "\n",
    "    if os.path.exists(train_data_dir):\n",
    "        print(f\"{train_data_dir} folder already exists. Skipping download.\")\n",
    "        return\n",
    "    \n",
    "    s3_resource = boto3.resource('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "    with open('file_list.json', 'r') as f:\n",
    "        d=json.load(f)\n",
    "\n",
    "    for k, v in d.items():\n",
    "        print(f\"Downloading Images with {k} objects\")\n",
    "        directory=os.path.join('train_data', k)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        for file_path in tqdm(v):\n",
    "            file_name=os.path.basename(file_path).split('.')[0]+'.jpg'\n",
    "            s3_resource.Bucket('aft-vbi-pds').download_file(os.path.join('bin-images', file_name), os.path.join(directory, file_name)) # type: ignore\n",
    "\n",
    "download_and_arrange_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "**TODO:** Explain what dataset you are using for this project. Give a small overview of the classes, class distributions etc that can help anyone not familiar with the dataset get a better understanding of it. You can find more information about the data [here](https://registry.opendata.aws/amazon-bin-imagery/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Perform any data cleaning or data preprocessing\n",
    "\n",
    "def preprocess_images(data_dir):\n",
    "    processed_images = []\n",
    "    labels = []\n",
    "    image_names = []\n",
    "    \n",
    "    for class_folder in os.listdir(data_dir):\n",
    "        class_path = os.path.join(data_dir, class_folder)\n",
    "        if os.path.isdir(class_path):\n",
    "            for image_file in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_file)\n",
    "                \n",
    "                try:\n",
    "                    # Open the image\n",
    "                    with Image.open(image_path) as img:\n",
    "                        # Convert to RGB if not already\n",
    "                        img = img.convert('RGB')\n",
    "                        \n",
    "                        # Resize the image (e.g., to 224x224 for many standard models)\n",
    "                        img = img.resize((224, 224))\n",
    "                        \n",
    "                        labels.append(class_folder)\n",
    "\n",
    "                        image_names.append(image_file)\n",
    "                        \n",
    "                        # Save processed image to BytesIO object\n",
    "                        buffer = BytesIO()\n",
    "                        img.save(buffer, format=\"JPEG\")\n",
    "                        buffer.seek(0)\n",
    "\n",
    "                        processed_images.append(buffer)\n",
    "                        \n",
    "                except (IOError, SyntaxError) as e:\n",
    "                    print(f\"Skipping corrupted image: {image_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return processed_images, labels, image_names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify some uploaded files in S3\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "\n",
    "def verify_some_uploaded_files(bucket_name):\n",
    "    sample = 'data/test/4/02573.jpg'\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=bucket_name, Key=sample)\n",
    "        print(f\"Verified {sample} is in {bucket_name}\")\n",
    "        return True\n",
    "    except s3_client.exceptions.NoSuchKey:\n",
    "        print(f\"{sample} not found in {bucket_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error verifying {sample}: {str(e)}\")\n",
    "\n",
    "# Verify some of the uploaded data\n",
    "is_uploaded = verify_some_uploaded_files(default_bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Upload the data to AWS S3\n",
    "\n",
    "def upload_data_to_s3(data, labels, image_names, bucket_name):\n",
    "    \n",
    "    for index, buffer in enumerate(data):\n",
    "        s3_key = f\"processed/{labels[index]}/{image_names[index]}\"\n",
    "        # Split data into train, test, and validation sets\n",
    "        train_ratio, test_ratio, valid_ratio = 0.6, 0.2, 0.2\n",
    "        \n",
    "        # Generate a random number for each image\n",
    "        random_num = np.random.random()\n",
    "        \n",
    "        if random_num < train_ratio:\n",
    "            s3_key = f\"data/train/{labels[index]}/{image_names[index]}\"\n",
    "        elif random_num < train_ratio + test_ratio:\n",
    "            s3_key = f\"data/test/{labels[index]}/{image_names[index]}\"\n",
    "        else:\n",
    "            s3_key = f\"data/valid/{labels[index]}/{image_names[index]}\"\n",
    "            \n",
    "        try:\n",
    "            s3_client.upload_fileobj(buffer, bucket_name, s3_key)\n",
    "            print(f\"Uploaded {image_names[index]} to {s3_key}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading {image_names[index]}: {str(e)}\")\n",
    "\n",
    "if is_uploaded:\n",
    "    print(\"Data already uploaded. Skipping upload.\")\n",
    "else:\n",
    "    processed_images, labels, image_names = preprocess_images(train_data_dir)\n",
    "    # Upload the data\n",
    "    upload_data_to_s3(processed_images, labels, image_names, default_bucket)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "**TODO:** This is the part where you can train a model. The type or architecture of the model you use is not important. \n",
    "\n",
    "**Note:** You will need to use the `train.py` script to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Declare your model training hyperparameter.\n",
    "#NOTE: You do not need to do hyperparameter tuning. You can use fixed hyperparameter values\n",
    "\n",
    "hyperparameters = {\n",
    "    'batch-size': 32,\n",
    "    'learning-rate': 0.001,\n",
    "    'momentum': 0.9,\n",
    "    'weight-decay': 1e-4,\n",
    "    'num-classes': 5,\n",
    "}\n",
    "\n",
    "# Print hyperparameters for logging\n",
    "print(\"Hyperparameters:\")\n",
    "for key, value in hyperparameters.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your training estimator\n",
    "\n",
    "# Define the training script\n",
    "training_script = 'train.py'\n",
    "\n",
    "# Define the framework version\n",
    "version = \"1.13.1\"\n",
    "\n",
    "#  Define the python version\n",
    "py_version = \"py39\"\n",
    "\n",
    "# Define the training instance type\n",
    "# instance_type = 'ml.c5.2xlarge'\n",
    "instance_type = 'ml.c6i.2xlarge'\n",
    "\n",
    "metric_definitions = [\n",
    "    {'Name': 'train:loss', 'Regex': 'Train Loss: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'test:loss', 'Regex': 'Average loss: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'test:accuracy', 'Regex': 'Accuracy: ([0-9\\\\.]+)'}\n",
    "]\n",
    "\n",
    "# Create the estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=training_script,\n",
    "    framework_version=version,\n",
    "    py_version=py_version,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    region=region,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=f\"s3://{default_bucket}/output\",\n",
    "    metric_definitions=metric_definitions,\n",
    "    dependencies=['requirements.txt'],\n",
    "    enable_sagemaker_metrics=True\n",
    ")\n",
    "\n",
    "\n",
    "# Split data for training\n",
    "train_input = TrainingInput(f\"s3://{default_bucket}/data/train\", content_type=\"application/x-image\")\n",
    "test_input = TrainingInput(f\"s3://{default_bucket}/data/test\", content_type=\"application/x-image\")\n",
    "valid_input = TrainingInput(f\"s3://{default_bucket}/data/valid\", content_type=\"application/x-image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py --batch_size 32 --learning_rate 0.001 --momentum 0.9 --num_classes 5 --weight_decay 0.0001\n",
    "# !python train.py --batch_size 32 --learning_rate 0.001 --momentum 0.9 --num_classes 5 --weight_decay 0.0001 --train-data ./train_data --test-data ./train_data --valid ./train_data --model-dir ./model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit your estimator\n",
    "# Set the data channels\n",
    "estimator.fit({\n",
    "    'train': train_input,\n",
    "    'test': test_input,\n",
    "    'valid': valid_input\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standout Suggestions\n",
    "You do not need to perform the tasks below to finish your project. However, you can attempt these tasks to turn your project into a more advanced portfolio piece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "**TODO:** Here you can perform hyperparameter tuning to increase the performance of your model. You are encouraged to \n",
    "- tune as many hyperparameters as you can to get the best performance from your model\n",
    "- explain why you chose to tune those particular hyperparameters and the ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your hyperparameter search space\n",
    "\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "hyperparameter_ranges = {\n",
    "    'batch-size': IntegerParameter(16, 32),\n",
    "    'learning-rate': ContinuousParameter(0.0001, 0.01),\n",
    "    'momentum': ContinuousParameter(0.8, 0.99),\n",
    "}\n",
    "\n",
    "# Define the objective metric\n",
    "objective_metric_name = 'test:loss'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your training estimator\n",
    "# Create the training estimator for hyperparameter tuning\n",
    "tuning_estimator = PyTorch(\n",
    "    entry_point=training_script,\n",
    "    base_job_name='pytorch-inventory-tuning',\n",
    "    role=role,\n",
    "    framework_version=version,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    py_version=py_version\n",
    ")\n",
    "\n",
    "# Create the hyperparameter tuner\n",
    "tuner = HyperparameterTuner(\n",
    "    tuning_estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions, # type: ignore\n",
    "    max_jobs=4,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type='Minimize'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit your estimator\n",
    "# Start the hyperparameter tuning job\n",
    "tuner.fit({\n",
    "    'train': train_input,\n",
    "    'test': test_input,\n",
    "    'valid': valid_input\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the best hyperparameters\n",
    "\n",
    "# Get the best training job\n",
    "best_training_job = tuner.best_training_job()\n",
    "\n",
    "# Attach to the best training job\n",
    "best_estimator = PyTorch.attach(best_training_job)\n",
    "\n",
    "# Print the hyperparameters of the best estimator\n",
    "print(\"Best Estimator Hyperparameters:\")\n",
    "best_hyperparameters = best_estimator.hyperparameters()\n",
    "\n",
    "# Update the hyperparameters dictionary with the best hyperparameters\n",
    "hyperparameters.update(best_hyperparameters) # type: ignore\n",
    "\n",
    "hyperparameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Profiling and Debugging\n",
    "**TODO:** Use model debugging and profiling to better monitor and debug your model training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up debugging and profiling rules and hooks\n",
    "# Define rules for debugging and profiling\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "]\n",
    "\n",
    "# Configure debugger hook\n",
    "hook_config = DebuggerHookConfig(\n",
    "    hook_parameters={\n",
    "        \"train.save_interval\": \"100\",  # Save every 100 steps\n",
    "        \"eval.save_interval\": \"10\"     # Save every 10 steps during evaluation\n",
    "    }\n",
    ")\n",
    "\n",
    "# Configure profiler\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=1000,  # Monitor system metrics every 1 second\n",
    "    framework_profile_params=FrameworkProfile(num_steps=10)  # Profile 10 steps\n",
    ")\n",
    "\n",
    "# Add a custom rule to detect loss not decreasing\n",
    "custom_loss_not_decreasing_rule = Rule.sagemaker(\n",
    "    base_config=rule_configs.loss_not_decreasing(),\n",
    "    rule_parameters={\n",
    "        \"threshold\": \"0.01\",\n",
    "        \"patience\": \"5\",\n",
    "        \"scan_interval_steps\": \"10\"\n",
    "    }\n",
    ")\n",
    "rules.append(custom_loss_not_decreasing_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and fit an estimator\n",
    "# Suggest using a more descriptive name for the estimator\n",
    "inventory_estimator = PyTorch(\n",
    "    entry_point='train.py',\n",
    "    base_job_name='inventory-monitoring',  # More descriptive job name\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    framework_version=version,\n",
    "    py_version=py_version,\n",
    "    hyperparameters=hyperparameters,\n",
    "    # Debugger and Profiler parameters\n",
    "    rules=rules,\n",
    "    debugger_hook_config=hook_config,\n",
    "    profiler_config=profiler_config,\n",
    ")\n",
    "\n",
    "# Suggest using a try-except block to handle potential errors during training\n",
    "try:\n",
    "    inventory_estimator.fit({\n",
    "        'train': train_input,\n",
    "        'test': test_input,\n",
    "        'valid': valid_input\n",
    "    })\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during training: {str(e)}\")\n",
    "    # Optionally, add more error handling or logging here\n",
    "\n",
    "# Suggest adding a print statement to confirm training completion\n",
    "print(\"Training completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot a debugging output.\n",
    "job_name = inventory_estimator.latest_training_job.job_name # type: ignore\n",
    "\n",
    "# Get the S3 path to the debugger artifacts\n",
    "debugger_artifacts_path = f\"s3://{default_bucket}/output/{job_name}/debug-output\"\n",
    "\n",
    "# Create a trial to access the debugger artifacts\n",
    "trial = create_trial(debugger_artifacts_path)\n",
    "\n",
    "# Example to get loss values\n",
    "losses = trial.tensor(\"CrossEntropyLoss_output_0\").values() # type: ignore\n",
    "\n",
    "epochs = list(range(1, len(losses) + 1))\n",
    "loss = [val for _, val in losses]\n",
    "\n",
    "plt.plot(epochs, loss, label='Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Is there some anomalous behaviour in your debugging output? If so, what is the error and how will you fix it?  \n",
    "**TODO**: If not, suppose there was an error. What would that error look like and how would you have fixed it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the profiler output\n",
    "\n",
    "rule_output_path = estimator.output_path + job_name + \"/rule-output\" # type: ignore\n",
    "\n",
    "# Convert AWS CLI command to boto3\n",
    "prefix = '/'.join(rule_output_path.split('/')[3:])  # Extract the prefix (folder path)\n",
    "\n",
    "# List objects in the S3 bucket with the given prefix\n",
    "response = s3_client.list_objects_v2(Bucket=default_bucket, Prefix=prefix)\n",
    "\n",
    "# Download each file\n",
    "for obj in response.get('Contents', []):\n",
    "    file_key = obj['Key']\n",
    "    file_name = file_key.split('/')[-1]  # Get the file name\n",
    "    s3_client.download_file(default_bucket, file_key, file_name)\n",
    "\n",
    "profiler_report_name = [\n",
    "    rule[\"RuleConfigurationName\"]\n",
    "    for rule in estimator.latest_training_job.rule_job_summary() # type: ignore\n",
    "    if \"Profiler\" in rule[\"RuleConfigurationName\"]\n",
    "][0]\n",
    "IPython.display.HTML(filename=profiler_report_name + \"/profiler-output/profiler-report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deploying and Querying\n",
    "**TODO:** Can you deploy your model to an endpoint and then query that endpoint to get a result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Deploy your model to an endpoint\n",
    "# Get the model data from the estimator\n",
    "model_data = str(inventory_estimator.model_data)\n",
    "print(f\"Model data location: {model_data}\")\n",
    "\n",
    "# Create a PyTorchModel for deployment\n",
    "pytorch_inference_model = PyTorchModel(\n",
    "    model_data=model_data,\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    entry_point='inference.py',\n",
    "    framework_version=version,\n",
    "    py_version=py_version,\n",
    ")\n",
    "\n",
    "# Deploy the model to an endpoint\n",
    "deployment = pytorch_inference_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    ")\n",
    "\n",
    "# Get the endpoint name for later use\n",
    "endpoint_name = pytorch_inference_model.endpoint_name\n",
    "print(f\"Model deployed to endpoint: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run a prediction on the endpoint\n",
    "\n",
    "# Initialize the predictor\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "# Set the serializer to handle image data\n",
    "predictor.serializer = IdentitySerializer(\"image/jpeg\")\n",
    "\n",
    "# Define the image path\n",
    "image_path = \"train_data/4/00059.jpg\"\n",
    "\n",
    "# Read the image file\n",
    "with open(image_path, \"rb\") as f:\n",
    "    payload = f.read()\n",
    "\n",
    "# Make a prediction\n",
    "response = predictor.predict(payload)\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remember to shutdown/delete your endpoint once your work is done\n",
    "\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheaper Training and Cost Analysis\n",
    "**TODO:** Can you perform a cost analysis of your system and then use spot instances to lessen your model training cost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost for training on a regular instance: $0.41\n",
      "Total cost for training on a spot instance: $0.34\n",
      "Cost savings by using a spot instance: $0.07\n"
     ]
    }
   ],
   "source": [
    "# TODO: Cost Analysis\n",
    "\n",
    "# Define the cost of training on a regular instance\n",
    "regular_instance_cost_per_hour = 0.204  # Example cost for ml.c5.xxlarge\n",
    "training_time_hours = 2  # Example training time\n",
    "\n",
    "# Calculate the total cost for training on a regular instance\n",
    "total_regular_instance_cost = regular_instance_cost_per_hour * training_time_hours\n",
    "print(f\"Total cost for training on a regular instance: ${total_regular_instance_cost:.2f}\")\n",
    "\n",
    "# Define the cost of training on a spot instance\n",
    "spot_instance_cost_per_hour = 0.17  # Example cost for ml.c5.xxlarge spot instance\n",
    "\n",
    "# Calculate the total cost for training on a spot instance\n",
    "total_spot_instance_cost = spot_instance_cost_per_hour * training_time_hours\n",
    "print(f\"Total cost for training on a spot instance: ${total_spot_instance_cost:.2f}\")\n",
    "\n",
    "# Calculate the cost savings\n",
    "cost_savings = total_regular_instance_cost - total_spot_instance_cost\n",
    "print(f\"Cost savings by using a spot instance: ${cost_savings:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train your model using a spot instance\n",
    "\n",
    "# Define the spot instance type\n",
    "train_use_spot_instances = True\n",
    "train_max_run = 3600\n",
    "train_max_wait = 3600 if train_use_spot_instances else None\n",
    "\n",
    "# Create the spot training estimator\n",
    "spot_estimator = PyTorch(\n",
    "    entry_point=training_script,\n",
    "    base_job_name=\"pytorch-inventory-spot\",\n",
    "    role=role,\n",
    "    instance_type=instance_type,\n",
    "    train_use_spot_instances=train_use_spot_instances,\n",
    "    train_max_run=train_max_run,\n",
    "    train_max_wait=train_max_wait,\n",
    "    instance_count=1,\n",
    "    framework_version=version,\n",
    "    py_version=py_version,\n",
    "    hyperparameters=hyperparameters,\n",
    "    rules=rules,\n",
    "    debugger_hook_config=hook_config,\n",
    "    profiler_config=profiler_config\n",
    ")\n",
    "\n",
    "spot_estimator.fit({\n",
    "    'train': train_input,\n",
    "    'test': test_input,\n",
    "    'valid': valid_input\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Instance Training\n",
    "**TODO:** Can you train your model on multiple instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train your model on Multiple Instances\n",
    "\n",
    "# Create the multi-instance training estimator\n",
    "multi_instance_estimator = PyTorch(\n",
    "    entry_point=training_script,\n",
    "    base_job_name=\"pytorch-inventory-multi-instance\",\n",
    "    role=role,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=2,\n",
    "    framework_version=version,\n",
    "    py_version=py_version,\n",
    "    hyperparameters=hyperparameters,\n",
    "    rules=rules,\n",
    "    debugger_hook_config=hook_config,\n",
    "    profiler_config=profiler_config\n",
    ")\n",
    "\n",
    "# Start the multi-instance training job\n",
    "multi_instance_estimator.fit({\n",
    "    'train': train_input,\n",
    "    'test': test_input,\n",
    "    'valid': valid_input\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
